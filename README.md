# Integrated Latent and Attention Mapping (ILAM) - IITBHU 

Medical image analysis demands advanced deep learning and image processing techniques to accurately classify disease categories. In breast cancer classification, leveraging both local and global features is crucial for accurately identifying and distinguishing cancerous regions. This project not only focuses on classification but also emphasizes the importance of explainability in medical AI models.
By incorporating both local and global features, we enhance the model’s decision-making process, ensuring that its classifications are informed by comprehensive image analysis. In the post-hoc stage, we generate detailed activation maps to visualize and explain the regions contributing to the model's decision, providing transparency and trust in the model's outputs.

Paper under review - ACM Transactions on Intelligent Systems and Technology
<h2><u>Research</u></h2>
<b>
  1. Grad-CAM: Visual Explanations from Deep Networks via Gradient-based Localization
  <br>
  <u>Paper:- https://arxiv.org/abs/</u>
</br>
  2. Graph-Based Manifold Ranking (Bottom-Up)
  <br>(i) Saliency Detection via Graph-Based Manifold Ranking
  <br>
  <u> <t>Paper:- https://openaccess.thecvf.com/content_cvpr_2013/papers/Yang_Saliency_Detection_via_2013_CVPR_paper.pdf</t></u>
  <br>
  (ii) Saliency Detection Based on Low-Level and High-Level Features via Manifold-Space Ranking
  <br>
  Paper:- https://www.mdpi.com/2079-9292/12/2/449
  <br>
  3. Resting State fMRI
  <br>
  Links:- 
  <br>
  (i) Overview - https://www.sciencedirect.com/topics/medicine-and-dentistry/resting-state-fmri
  <br>
  (ii) Paper - https://paperswithcode.com/paper/eag-rs-a-novel-explainability-guided-roi
  (IEEE Transactions Journal 5 Oct,2023) 
  <br>
  (iii) Approaches - https://ars.els-cdn.com/content/image/1-s2.0-B9780444641489000193-f19-01-9780444641489.jpg
</b>





## Proposed Model Performance Analysis across 40X, 100X, 200X, 400X Magnifications on Breakhis Dataset

| Magnification | Model   | Accuracy (%)       | Precision (%)      | Recall (%)        | F1-Score (%)       | ROC-Score (%)      |
|---------------|---------|--------------------|--------------------|-------------------|--------------------|--------------------|
| 40X           | Ours    | 83.84 ± 4.24       | 84.26 ± 2.76       | 93.01 ± 4.43      | 88.40 ± 3.27       | 79.22 ± 4.47       |
|               | CvT     | 76.25 ± 0.86       | 79.10 ± 1.13       | 85.93 ± 0.27      | 82.37 ± 0.48       | 72.26 ± 1.32       |
|               | DeiT    | 77.05 ± 0.34       | 77.08 ± 2.25       | 92.05 ± 5.18      | 83.78 ± 1.03       | 70.89 ± 1.64       |
|               | ViT     | 82.08 ± 6.27       | 84.04 ± 6.05       | 90.47 ± 3.38      | 87.08 ± 4.38       | 78.00 ± 8.27       |
| 100X          | Ours    | 83.51 ± 3.93       | 86.02 ± 5.14       | 90.26 ± 3.47      | 87.98 ± 2.67       | 80.27 ± 5.67       |
|               | CvT     | 80.08 ± 1.54       | 82.04 ± 1.22       | 89.26 ± 0.94      | 85.50 ± 1.09       | 75.84 ± 1.82       |
|               | DeiT    | 76.65 ± 0.50       | 75.00 ± 0.84       | 96.86 ± 3.19      | 84.50 ± 0.74       | 67.33 ± 0.74       |
|               | ViT     | 79.97 ± 3.73       | 80.68 ± 4.56       | 92.53 ± 4.64      | 86.06 ± 2.35       | 73.86 ± 5.53       |
| 200X          | Ours    | 89.35 ± 3.03       | 88.27 ± 3.31       | 97.13 ± 1.83      | 92.46 ± 2.04       | 85.37 ± 4.27       |
|               | CvT     | 83.99 ± 0.17       | 82.31 ± 0.64       | 95.77 ± 1.46      | 88.53 ± 0.27       | 79.18 ± 0.36       |
|               | DeiT    | 81.00 ± 3.00       | 78.73 ± 3.59       | 96.96 ± 0.80      | 86.85 ± 1.78       | 74.48 ± 4.56       |
|               | ViT     | 87.39 ± 4.64       | 87.53 ± 6.02       | 95.12 ± 3.67      | 91.03 ± 3.24       | 83.74 ± 6.51       |
| 400X          | Ours    | 86.46 ± 3.36       | 87.27 ± 3.51       | 92.69 ± 2.38      | 89.88 ± 2.70       | 83.72 ± 3.64       |
|               | CvT     | 84.01 ± 0.19       | 82.88 ± 0.05       | 93.00 ± 0.48      | 87.65 ± 0.19       | 81.47 ± 0.11       |
|               | DeiT    | 83.22 ± 0.00       | 83.11 ± 0.10       | 91.00 ± 0.16      | 86.87 ± 0.02       | 81.03 ± 0.05       |
|               | ViT     | 85.68 ± 2.65       | 84.94 ± 1.11       | 94.89 ± 2.59      | 89.63 ± 1.71       | 81.41 ± 4.03       |

## Explainability Analysis on Benign Sample accross different Magnifications

![image](https://github.com/user-attachments/assets/75fa88ab-5aee-4f15-9f9b-1c932cbdf8d9)



## Explainability Analysis on Malignant Sample accross different Magnifications

![image](https://github.com/user-attachments/assets/667b75b6-8f3f-41a5-bb36-f037304f4a2b)




## References 
1. Samira Abnar and Willem Zuidema. 2020. Quantifying Attention Flow in Transformers.
2. Moritz Böhle, Mario Fritz, and Bernt Schiele. 2023. Holistically Explainable Vision Transformers.
3. Wonsik Jung, Eunjin Jeon, Eunsong Kang, and Heung-Il Suk. 2024. *EAG-RS: A Novel Explainability-Guided ROI-Selection Framework for ASD Diagnosis via Inter-Regional Relation Learning*. IEEE Transactions on Medical Imaging.
4. Fabio A. Spanhol, Luiz S. Oliveira, Caroline Petitjean, and Laurent Heutte. 2016. *A Dataset for Breast Cancer Histopathological Image Classification*. IEEE Transactions on Biomedical Engineering.

https://medium.com/@brianpulfer/vision-transformers-from-scratch-pytorch-a-step-by-step-guide-96c3313c2e0c
